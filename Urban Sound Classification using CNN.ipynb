{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [Root]",
      "language": "python",
      "name": "Python [Root]"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.12"
    },
    "colab": {
      "name": "Urban Sound Classification using CNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/finlaymiller/Urban-Sound-Classification/blob/master/Urban%20Sound%20Classification%20using%20CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zmG-ROGeO0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_2PJKQwPkCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "plt.rcParams['font.family'] = 'sans-serif'\n",
        "plt.rcParams['font.serif'] = 'Ubuntu'\n",
        "plt.rcParams['font.monospace'] = 'Ubuntu Mono'\n",
        "plt.rcParams['font.size'] = 12\n",
        "plt.rcParams['axes.labelsize'] = 11\n",
        "plt.rcParams['axes.labelweight'] = 'bold'\n",
        "plt.rcParams['axes.titlesize'] = 12\n",
        "plt.rcParams['xtick.labelsize'] = 9\n",
        "plt.rcParams['ytick.labelsize'] = 9\n",
        "plt.rcParams['legend.fontsize'] = 11\n",
        "plt.rcParams['figure.titlesize'] = 13"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ92AWgFPkDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def windows(data, window_size):\n",
        "    start = 0\n",
        "    while start < len(data):\n",
        "        yield int(start), int(start + window_size)\n",
        "        start += (window_size / 2)\n",
        "\n",
        "def extract_features(parent_dir,sub_dirs,file_ext=\"*.wav\",bands = 60, frames = 41):\n",
        "    window_size = 512 * (frames - 1)\n",
        "    log_specgrams = []\n",
        "    labels = []\n",
        "    for l, sub_dir in enumerate(sub_dirs):\n",
        "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
        "            sound_clip,s = librosa.load(fn)\n",
        "            label = fn.split('/')[-1].split('-')[1]\n",
        "            for (start,end) in windows(sound_clip,window_size):\n",
        "                if(len(sound_clip[start:end]) == window_size):\n",
        "                    signal = sound_clip[start:end]\n",
        "                    melspec = librosa.feature.melspectrogram(signal, n_mels = bands)\n",
        "                    logspec = librosa.amplitude_to_db(melspec)\n",
        "                    logspec = logspec.T.flatten()[:, np.newaxis].T\n",
        "                    log_specgrams.append(logspec)\n",
        "                    labels.append(label)\n",
        "            \n",
        "    log_specgrams = np.asarray(log_specgrams).reshape(len(log_specgrams),bands,frames,1)\n",
        "    features = np.concatenate((log_specgrams, np.zeros(np.shape(log_specgrams))), axis = 3)\n",
        "    for i in range(len(features)):\n",
        "        features[i, :, :, 1] = librosa.feature.delta(features[i, :, :, 0])\n",
        "    \n",
        "    return np.array(features), np.array(labels,dtype = np.int)\n",
        "\n",
        "def one_hot_encode(labels):\n",
        "    n_labels = len(labels)\n",
        "    n_unique_labels = len(np.unique(labels))\n",
        "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
        "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
        "    return one_hot_encode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUxw8PNCPkDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parent_dir = 'drive/My Drive/sample-sounds'\n",
        "sub_dirs= ['fold1','fold2']\n",
        "features,labels = extract_features(parent_dir,sub_dirs)\n",
        "labels = one_hot_encode(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVMo65ihPkD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weight_variable(shape):\n",
        "    initial = tf.truncated_normal(shape, stddev = 0.1)\n",
        "    return tf.Variable(initial)\n",
        "\n",
        "def bias_variable(shape):\n",
        "    initial = tf.constant(1.0, shape = shape)\n",
        "    return tf.Variable(initial)\n",
        "\n",
        "def conv2d(x, W):\n",
        "    return tf.nn.conv2d(x,W,strides=[1,2,2,1], padding='SAME')\n",
        "\n",
        "def apply_convolution(x,kernel_size,num_channels,depth):\n",
        "    weights = weight_variable([kernel_size, kernel_size, num_channels, depth])\n",
        "    biases = bias_variable([depth])\n",
        "    return tf.nn.relu(tf.add(conv2d(x, weights),biases))\n",
        "\n",
        "def apply_max_pool(x,kernel_size,stride_size):\n",
        "    return tf.nn.max_pool(x, ksize=[1, kernel_size, kernel_size, 1], \n",
        "                          strides=[1, stride_size, stride_size, 1], padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83xYq31ePkET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnd_indices = np.random.rand(len(labels)) < 0.70\n",
        "\n",
        "train_x = features[rnd_indices]\n",
        "train_y = labels[rnd_indices]\n",
        "test_x = features[~rnd_indices]\n",
        "test_y = labels[~rnd_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNI4gexnPkEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frames = 41\n",
        "bands = 60\n",
        "\n",
        "feature_size = 2460 #60x41\n",
        "num_labels = 10\n",
        "num_channels = 2\n",
        "\n",
        "batch_size = 50\n",
        "kernel_size = 30\n",
        "depth = 20\n",
        "num_hidden = 200\n",
        "\n",
        "learning_rate = 0.01\n",
        "training_iterations = 2000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN4wGzu1PkE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.placeholder(tf.float32, shape=[None,bands,frames,num_channels])\n",
        "Y = tf.placeholder(tf.float32, shape=[None,num_labels])\n",
        "\n",
        "cov = apply_convolution(X,kernel_size,num_channels,depth)\n",
        "\n",
        "shape = cov.get_shape().as_list()\n",
        "cov_flat = tf.reshape(cov, [-1, shape[1] * shape[2] * shape[3]])\n",
        "\n",
        "f_weights = weight_variable([shape[1] * shape[2] * depth, num_hidden])\n",
        "f_biases = bias_variable([num_hidden])\n",
        "f = tf.nn.sigmoid(tf.add(tf.matmul(cov_flat, f_weights),f_biases))\n",
        "\n",
        "out_weights = weight_variable([num_hidden, num_labels])\n",
        "out_biases = bias_variable([num_labels])\n",
        "y_ = tf.nn.softmax(tf.matmul(f, out_weights) + out_biases)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGHYRvEaPkFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = -tf.reduce_sum(Y * tf.log(y_))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy)\n",
        "correct_prediction = tf.equal(tf.argmax(y_,1), tf.argmax(Y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "wuwzyyP6PkFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cost_history = np.empty(shape=[1],dtype=float)\n",
        "with tf.Session() as session:\n",
        "    tf.global_variables_initializer().run()\n",
        "\n",
        "    for itr in range(training_iterations):    \n",
        "        offset = (itr * batch_size) % (train_y.shape[0] - batch_size)\n",
        "        batch_x = train_x[offset:(offset + batch_size), :, :, :]\n",
        "        batch_y = train_y[offset:(offset + batch_size), :]\n",
        "        \n",
        "        _, c = session.run([optimizer, cross_entropy],feed_dict={X: batch_x, Y : batch_y})\n",
        "        cost_history = np.append(cost_history,c)\n",
        "    \n",
        "    print('Test accuracy: ',round(sess.run(accuracy, feed_dict={X: test_x, Y: test_y}) , 3))\n",
        "    fig = plt.figure(figsize=(15,10))\n",
        "    plt.plot(cost_history)\n",
        "    plt.axis([0,training_iterations,0,np.max(cost_history)])\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}